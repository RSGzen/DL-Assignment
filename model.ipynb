{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f234f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "268c6c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# CUSTOM EFFICIENTNET IMPLEMENTATION\n",
    "# =======================\n",
    "\n",
    "class CustomMBConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expand_ratio, kernel_size, stride, se_ratio=0.25):\n",
    "        super(CustomMBConvBlock, self).__init__()\n",
    "        self.stride = stride # store the stride for foward pass\n",
    "        self.expand_ratio = expand_ratio # store the expansion ratio for conditional logic\n",
    "        \n",
    "        mid_channels = int(in_channels * expand_ratio)\n",
    "        \n",
    "        self.expand_conv = nn.Conv2d(in_channels, mid_channels, kernel_size=1, bias=False) if expand_ratio != 1 else None # add 1x1 convolutional layer to increase the number of channel\n",
    "        self.bn0 = nn.BatchNorm2d(mid_channels) if expand_ratio != 1 else None # batch normalization for the expand channel\n",
    "        \n",
    "        self.depthwise_conv = nn.Conv2d(\n",
    "            mid_channels if expand_ratio != 1 else in_channels,\n",
    "            mid_channels if expand_ratio != 1 else in_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=kernel_size // 2, #ensure the output spatial dimension are preserved\n",
    "            groups=mid_channels if expand_ratio != 1 else in_channels,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(mid_channels if expand_ratio != 1 else in_channels) # batch normalize after the depthwise convolution\n",
    "        \n",
    "        se_channels = max(1, int(in_channels * se_ratio))  # Squeeze-and-Excitation (SE) block\n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1), \n",
    "            nn.Conv2d(mid_channels if expand_ratio != 1 else in_channels, se_channels, kernel_size=1),# reduce channel to sechannel \n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(se_channels, mid_channels if expand_ratio != 1 else in_channels, kernel_size=1), # expand back to the original number of channel \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.reduce_conv = nn.Conv2d( # reduce the number of channel to outchannel using 1x1 convolution\n",
    "            mid_channels if expand_ratio != 1 else in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels) # batch normalization after the reduction convolution\n",
    "        \n",
    "        self.use_residual = in_channels == out_channels and stride == 1 # residual connection is apply if the input and output channel match and the stride is 1\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x # store x as identity for the residual connection\n",
    "        \n",
    "        if self.expand_ratio != 1: #apply 1x1 convolution , batch normalization and Silu activation \n",
    "            x = self.expand_conv(x)\n",
    "            x = self.bn0(x)\n",
    "            x = nn.functional.silu(x)\n",
    "        \n",
    "        x = self.depthwise_conv(x) # apply depthwise convolution , batch normalization andSilu activation \n",
    "        x = self.bn1(x)\n",
    "        x = nn.functional.silu(x)\n",
    "        \n",
    "        se = self.se(x) # compute attention weight through SE block and scales the channel\n",
    "        x = x * se\n",
    "        \n",
    "        x = self.reduce_conv(x) # apply 1x1 convolution and batch normalization to reduce channel\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        if self.use_residual:\n",
    "            x = x + identity\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00471d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEfficientNet(nn.Module):\n",
    "    def __init__(self, config, pretrained=False):\n",
    "        super(CustomEfficientNet, self).__init__()\n",
    "        \n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, config['stem_channels'], kernel_size=3, stride=2, padding=1, bias=False), # 3x3 convolution with stride 2 (downsampling spatial dimension by 2)\n",
    "            nn.BatchNorm2d(config['stem_channels']),# normalize the output\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        \n",
    "        self.blocks = nn.ModuleList()\n",
    "        in_channels = config['stem_channels']\n",
    "        \n",
    "        for stage in config['stages']: # iterate over stage in config. where each stage define a group of blocks\n",
    "            num_layers = stage['num_layers']\n",
    "            out_channels = stage['out_channels']\n",
    "            expand_ratio = stage['expand_ratio']\n",
    "            kernel_size = stage['kernel_size']\n",
    "            stride = stage['stride']\n",
    "            \n",
    "            for i in range(num_layers):\n",
    "                block_stride = stride if i == 0 else 1\n",
    "                self.blocks.append(\n",
    "                    CustomMBConvBlock(\n",
    "                        in_channels=in_channels,\n",
    "                        out_channels=out_channels,\n",
    "                        expand_ratio=expand_ratio,\n",
    "                        kernel_size=kernel_size,\n",
    "                        stride=block_stride,\n",
    "                        se_ratio=0.25\n",
    "                    )\n",
    "                )\n",
    "                in_channels = out_channels\n",
    "        \n",
    "        self.head = nn.Sequential( #final convolutional layer to prepare features for pooling \n",
    "            nn.Conv2d(in_channels, config['head_channels'], kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(config['head_channels']),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1) # average pooling to reduce spatial dimension to 1x1\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(config['head_channels'], 1000)\n",
    "        )\n",
    "        \n",
    "        if not pretrained:\n",
    "            self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d): #set weight to 1 and bias to 0\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.stem(x) \n",
    "        for block in self.blocks:\n",
    "            x = block(x) \n",
    "        x = self.head(x) \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a7f388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# MODIFIED EFFICIENTNETFER CLASS\n",
    "# =======================\n",
    "\n",
    "class EfficientNetFER(nn.Module):\n",
    "    def __init__(self, num_classes=7, pretrained=False, device='cpu', custom_fc_dims=[512, 256], \n",
    "                 dropout=0.3, use_post_conv=False, efficientnet_config=None):\n",
    "        super(EfficientNetFER, self).__init__()\n",
    "        self.device = device\n",
    "        self.use_post_conv = use_post_conv\n",
    "        \n",
    "        default_config = {\n",
    "            'stem_channels': 32, # number of output channel for initial convolutional layer\n",
    "            'head_channels': 1280, # number of channel before the final classifier\n",
    "            'stages': [\n",
    "                {'num_layers': 1, 'out_channels': 16, 'expand_ratio': 1, 'kernel_size': 3, 'stride': 1},\n",
    "                {'num_layers': 2, 'out_channels': 24, 'expand_ratio': 6, 'kernel_size': 3, 'stride': 2},\n",
    "                {'num_layers': 2, 'out_channels': 40, 'expand_ratio': 6, 'kernel_size': 5, 'stride': 2},\n",
    "                {'num_layers': 3, 'out_channels': 80, 'expand_ratio': 6, 'kernel_size': 3, 'stride': 2},\n",
    "                {'num_layers': 3, 'out_channels': 112, 'expand_ratio': 6, 'kernel_size': 5, 'stride': 1},\n",
    "                {'num_layers': 4, 'out_channels': 192, 'expand_ratio': 6, 'kernel_size': 5, 'stride': 2},\n",
    "                {'num_layers': 1, 'out_channels': 320, 'expand_ratio': 6, 'kernel_size': 3, 'stride': 1},\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        self.config = efficientnet_config if efficientnet_config else default_config\n",
    "        \n",
    "        self.efficientnet = CustomEfficientNet(self.config, pretrained=pretrained)\n",
    "        self.efficientnet.to(device)\n",
    "        \n",
    "        for param in self.efficientnet.parameters():\n",
    "            param.requires_grad = False # disable gradient computation for all Efficientnet parameter\n",
    "        \n",
    "        if self.use_post_conv:\n",
    "            self.post_conv = nn.Sequential(# additional convolutional block is added after the efficientnet head\n",
    "                nn.Conv2d(self.config['head_channels'], 512, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(512), \n",
    "                nn.ReLU(),\n",
    "                nn.AdaptiveAvgPool2d(1) # reduce the spatial dimension to 1x1 (global average pooling)\n",
    "            ).to(device)\n",
    "            fc_input_features = 512\n",
    "        else:\n",
    "            fc_input_features = self.config['head_channels'] # 1280\n",
    "        \n",
    "        layers = [nn.Dropout(dropout)] # dropout to prevent overfitting\n",
    "        in_dim = fc_input_features\n",
    "        for out_dim in custom_fc_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(in_dim, out_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            in_dim = out_dim \n",
    "        layers.append(nn.Linear(in_dim, num_classes)) # set a final linear to map the num class\n",
    "        \n",
    "        self.classifier = nn.Sequential(*layers).to(device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.efficientnet.stem(x)\n",
    "        for block in self.efficientnet.blocks:\n",
    "            x = block(x)# iterate through each block , applying the efficientnet architecture\n",
    "        x = self.efficientnet.head(x)\n",
    "        \n",
    "        if self.use_post_conv:\n",
    "            x = self.post_conv(x)\n",
    "        else:\n",
    "            x = self.efficientnet.avgpool(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1) \n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def unfreeze_layers(self, num_layers=5):# unfreeze specific layer for fine tuning , allow the parameter to be updated during training\n",
    "        for param in self.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "        layers = list(self.efficientnet.blocks[-num_layers:]) + [self.efficientnet.head] # select  the last numlayers blocks of the efficient and head\n",
    "        if self.use_post_conv:\n",
    "            layers.append(self.post_conv)\n",
    "        for layer in layers:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84bf1d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=25, device='cuda', patience=5):\n",
    "    #criterion (loss function)\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        model.train() # put layer to training mode ( dropout/batch-norm)\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        for inputs, labels in tqdm(train_loader, desc='Training'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad() \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels) # compute the loss between prediction and true label \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset) \n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset) \n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_acc'].append(epoch_acc.item())\n",
    "        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "        \n",
    "        with torch.inference_mode:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_corrects = 0\n",
    "            with torch.no_grad():# disable the gradient computation as gradient are not needed during validation\n",
    "                for inputs, labels in tqdm(val_loader, desc='Validation'):\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1) # get predicted class indices\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item() * inputs.size(0)\n",
    "                    val_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            val_epoch_loss = val_loss / len(val_loader.dataset) \n",
    "            val_epoch_acc = val_corrects.double() / len(val_loader.dataset) \n",
    "            history['val_loss'].append(val_epoch_loss)\n",
    "            history['val_acc'].append(val_epoch_acc.item())\n",
    "            print(f'Val Loss: {val_epoch_loss:.4f} Acc: {val_epoch_acc:.4f}')\n",
    "        \n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(val_epoch_loss) # use validation loss to decide whether to reduce learning rate \n",
    "        else:\n",
    "            scheduler.step() # update the learning rate based on the epoch count \n",
    "        \n",
    "        if val_epoch_acc > best_acc:\n",
    "            best_acc = val_epoch_acc\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        \n",
    "        if epoch - best_epoch > patience:\n",
    "            print(f'Early stopping at epoch {epoch}') # if the validation accuracy hasnt improved , training stop to prevent overfitting \n",
    "            break\n",
    "    \n",
    "    print(f'Best val Acc: {best_acc:.4f} at epoch {best_epoch}')\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab82d1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA not available. Using CPU.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CustomEfficientNet' object has no attribute '_initialize_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     28\u001b[39m val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     29\u001b[39m custom_config = {\n\u001b[32m     30\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mstem_channels\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m32\u001b[39m, \u001b[38;5;66;03m# number of output channel in the initial layer of the network. Stem is the first convolutional layer that process the input image\u001b[39;00m\n\u001b[32m     31\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhead_channels\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1280\u001b[39m, \u001b[38;5;66;03m#number of channels in the final feature map \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     40\u001b[39m     ]\n\u001b[32m     41\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m model = \u001b[43mEfficientNetFER\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_fc_dims\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_post_conv\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43mefficientnet_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_config\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(model.efficientnet.blocks)\n\u001b[32m     55\u001b[39m criterion = nn.CrossEntropyLoss()\u001b[38;5;66;03m# combine log softmax and negative log likelihood loss , suitable for multi class classification\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mEfficientNetFER.__init__\u001b[39m\u001b[34m(self, num_classes, pretrained, device, custom_fc_dims, dropout, use_post_conv, efficientnet_config)\u001b[39m\n\u001b[32m     12\u001b[39m default_config = {\n\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mstem_channels\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m32\u001b[39m, \u001b[38;5;66;03m# number of output channel for initial convolutional layer\u001b[39;00m\n\u001b[32m     14\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhead_channels\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1280\u001b[39m, \u001b[38;5;66;03m# number of channel before the final classifier\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     ]\n\u001b[32m     24\u001b[39m }\n\u001b[32m     26\u001b[39m \u001b[38;5;28mself\u001b[39m.config = efficientnet_config \u001b[38;5;28;01mif\u001b[39;00m efficientnet_config \u001b[38;5;28;01melse\u001b[39;00m default_config\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28mself\u001b[39m.efficientnet = \u001b[43mCustomEfficientNet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mself\u001b[39m.efficientnet.to(device)\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.efficientnet.parameters():\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mCustomEfficientNet.__init__\u001b[39m\u001b[34m(self, config, pretrained)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28mself\u001b[39m.classifier = nn.Sequential(\n\u001b[32m     44\u001b[39m     nn.Dropout(\u001b[32m0.2\u001b[39m),\n\u001b[32m     45\u001b[39m     nn.Linear(config[\u001b[33m'\u001b[39m\u001b[33mhead_channels\u001b[39m\u001b[33m'\u001b[39m], \u001b[32m1000\u001b[39m)\n\u001b[32m     46\u001b[39m )\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pretrained:\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize_weights\u001b[49m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1940\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1938\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1939\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1941\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1942\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'CustomEfficientNet' object has no attribute '_initialize_weights'"
     ]
    }
   ],
   "source": [
    "## Model Setup\n",
    "\n",
    "batch_size = 128 \n",
    "num_epochs = 50 # number of time entire training dataset is passed through model\n",
    "learning_rate = 0.001\n",
    "num_classes = 7\n",
    "\n",
    "if torch.cuda.is_available():# determine to use GPU or CPU for training \n",
    "    device = torch.device('cuda')\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"CUDA not available. Using CPU.\")\n",
    "\n",
    "base_dir = os.getcwd()\n",
    "train_dir = os.path.join(base_dir, \"processed_data\", \"train\")\n",
    "val_dir = os.path.join(base_dir, \"processed_data\", \"validation\")\n",
    "\n",
    "transformation = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True), # Convert image to float ranging from 0 - 1\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(train_dir, transform=transformation)\n",
    "val_dataset = ImageFolder(val_dir, transform=transformation)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "custom_config = {\n",
    "    'stem_channels': 32, # number of output channel in the initial layer of the network. Stem is the first convolutional layer that process the input image\n",
    "    'head_channels': 1280, #number of channels in the final feature map \n",
    "    'stages': [\n",
    "        {'num_layers': 1, 'out_channels': 16, 'expand_ratio': 1, 'kernel_size': 3, 'stride': 1},\n",
    "        {'num_layers': 2, 'out_channels': 24, 'expand_ratio': 6, 'kernel_size': 3, 'stride': 2},\n",
    "        {'num_layers': 2, 'out_channels': 40, 'expand_ratio': 6, 'kernel_size': 5, 'stride': 2},\n",
    "        {'num_layers': 3, 'out_channels': 80, 'expand_ratio': 6, 'kernel_size': 3, 'stride': 2},\n",
    "        {'num_layers': 3, 'out_channels': 112, 'expand_ratio': 6, 'kernel_size': 5, 'stride': 1},\n",
    "        {'num_layers': 4, 'out_channels': 192, 'expand_ratio': 6, 'kernel_size': 5, 'stride': 2},\n",
    "        {'num_layers': 1, 'out_channels': 320, 'expand_ratio': 6, 'kernel_size': 3, 'stride': 1},\n",
    "    ]\n",
    "}\n",
    "\n",
    "model = EfficientNetFER(\n",
    "    num_classes=num_classes,\n",
    "    device=device,\n",
    "    pretrained=False,\n",
    "    custom_fc_dims=[512, 256],\n",
    "    dropout=0.4,\n",
    "    use_post_conv=True,\n",
    "    efficientnet_config=custom_config\n",
    ")\n",
    "\n",
    "print(model.efficientnet.blocks)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()# combine log softmax and negative log likelihood loss , suitable for multi class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)#reduce learning rate by a factor of 0.1 if validation loss doesnt improve for 3 epochs. Help model converge better\n",
    "\n",
    "# Print out model summary\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77031586",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Training\n",
    "\n",
    "history = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler,\n",
    "                          num_epochs=num_epochs, device=device)\n",
    "    \n",
    "print(\"Starting fine-tuning...\")\n",
    "model.unfreeze_layers(num_layers=5)#unfreeze the last 5 layers to allow them to adapt the FER task\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate / 10)# create a new optimizer only for unfrozen parameter with reduced learning rate to make more smaller and more precise update\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "\n",
    "history_ft = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler,\n",
    "                            num_epochs=num_epochs // 2, device=device)\n",
    "\n",
    "for key in history:\n",
    "    history[key].extend(history_ft[key])# combine the training and fine tuning histories into single history dictionary .\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff67d957",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking and saving trained model\n",
    "\n",
    "# Print model's state dictionary\n",
    "for paramTensor in model.state_dict():\n",
    "    print(paramTensor, \"\\t\", model.state_dict()[paramTensor].size())\n",
    "\n",
    "# Print optimizer's state dictionary\n",
    "for varName in optimizer.state_dict():\n",
    "    print(varName, \"\\t\", optimizer.state_dict()[varName])\n",
    "\n",
    "# Save trained model\n",
    "\n",
    "base_path = os.getcwd()\n",
    "folder_path = os.path.join(base_path, \"model\")\n",
    "\n",
    "if not os.path.isdir(folder_path):\n",
    "    os.mkdir(folder_path)\n",
    "\n",
    "model_name = \"model_1\"\n",
    "\n",
    "model_path = os.path.join(folder_path, model_name)\n",
    "\n",
    "if not os.path.isdir(model_path):\n",
    "    os.mkdir(model_path)\n",
    "\n",
    "modelStateDictName = model_name + \"_weights.pth\"\n",
    "modelEntireName = model_name + \".pth\"\n",
    "\n",
    "modelStateDict_path = os.path.join(model_path, modelStateDictName)\n",
    "modelEntire_path = os.path.join(model_path, modelEntireName)\n",
    "\n",
    "# Save model's weight only\n",
    "if os.path.isdir(modelStateDict_path):\n",
    "    print(f\"\\n{model_name} state dictionary file existed previously. New {model_name}'s state is not saved.\")\n",
    "else:\n",
    "    torch.save(model.state_dict(), modelStateDict_path)\n",
    "    print(f\"\\n{model_name}'s state file has been successfully saved.\")\n",
    "\n",
    "# Save entire model including layers and weights\n",
    "if os.path.isdir(modelEntire_path):\n",
    "    print(f\"\\n{model_name} file existed previously. New {model_name} is not saved.\")\n",
    "else:\n",
    "    torch.save(model, modelEntire_path)\n",
    "    print(f\"\\n{model_name} has been successfully saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393036b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing model's training history dictionary to file\n",
    "\n",
    "json_path = os.path.join(model_path, \"history.json\")\n",
    "\n",
    "if os.path.isdir(json_path):\n",
    "    print(f\"\\n{model_name}'s history file existed previously. New {model_name}'s history file is not saved.\")\n",
    "else:\n",
    "    with open(json_path, 'w') as file:\n",
    "        json.dump(history, file)\n",
    "    \n",
    "    print(f\"{model_name}'s training history has been saved.\")\n",
    "\n",
    "# Checking model's training history\n",
    "\n",
    "for x in history:\n",
    "    print(history)\n",
    "    for y in history[x]:\n",
    "        print(y, ':', history[x][y])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
